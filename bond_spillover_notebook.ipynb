{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Euro Area Bond Yield Spillover Analysis\n",
    "## Diebold-Yilmaz (2012) Generalized FEVD Framework\n",
    "\n",
    "**What this notebook does:**\n",
    "- Loads daily 10-year sovereign bond yield data for 7 countries (US, Japan, UK, Germany, France, Italy, Spain)\n",
    "- Estimates a Vector Autoregression (VAR) model on yield *changes*\n",
    "- Computes **Generalized Forecast Error Variance Decomposition** (GFEVD) \u2014 an order-invariant method\n",
    "- Rolls this estimation through time to produce time-varying spillover measures\n",
    "- Generates charts and tables summarising who affects whom in global bond markets\n",
    "\n",
    "**Key references:**\n",
    "- Diebold & Yilmaz (2009, 2012): Spillover index methodology\n",
    "- Pesaran & Shin (1998): Generalized impulse responses and FEVD (order-invariant)\n",
    "- Kl\u00f6ssner & Wagner (2014): Exploration of all VAR orderings (motivates the Generalized approach)\n",
    "\n",
    "**How to re-run with different settings:** Change the parameters in Section 2 and re-run all cells."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup & Package Installation\n",
    "\n",
    "The cell below installs any missing packages. If you're on Cloudera, you may need to run this once.\n",
    "After that, it imports everything we need.\n",
    "\n",
    "| Package | Purpose |\n",
    "|---------|---------|\n",
    "| `pandas` | Data manipulation (DataFrames) |\n",
    "| `numpy` | Numerical computation (matrix algebra for FEVD) |\n",
    "| `matplotlib` | Plotting charts |\n",
    "| `statsmodels` | VAR model estimation |\n",
    "| `scipy` | Statistical tests |\n",
    "| `openpyxl` | Excel file export |"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Install missing packages (run once, then comment out if needed)\n",
    "import subprocess, sys\n",
    "for pkg in ['pandas', 'numpy', 'matplotlib', 'statsmodels', 'scipy', 'openpyxl']:\n",
    "    try:\n",
    "        __import__(pkg)\n",
    "    except ImportError:\n",
    "        subprocess.check_call([sys.executable, '-m', 'pip', 'install', pkg, '-q'])\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.api import VAR\n",
    "from scipy import stats\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.dpi'] = 120\n",
    "plt.rcParams['figure.figsize'] = (12, 5)\n",
    "\n",
    "print(\"All packages loaded successfully.\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configuration \u2014 Parameters You Can Change\n",
    "\n",
    "**All tuneable parameters are in the cell below.** Change them here and re-run the notebook.\n",
    "\n",
    "| Parameter | Default | What it controls | Typical range |\n",
    "|-----------|---------|-----------------|---------------|\n",
    "| `VAR_LAGS` | 4 | Number of lags in the VAR model | 2\u20136 for daily data |\n",
    "| `FORECAST_HORIZON` | 10 | Days ahead for variance decomposition | 5\u201320 |\n",
    "| `ROLLING_WINDOW` | 200 | Trading days per rolling window (~10 months) | 100\u2013500 |\n",
    "| `STEP_SIZE` | 5 | Days between successive windows (speed vs smoothness) | 1\u201310 |\n",
    "| `DATA_PATH` | `nav_test_clean.csv` | Input CSV file path | Any CSV with same column format |\n",
    "\n",
    "**Country lists** \u2014 you can add or remove countries if your CSV has more columns:\n",
    "- `EXTERNAL`: Countries outside the Euro Area\n",
    "- `EA_CORE`: Core EA members\n",
    "- `EA_PERIPHERY`: Peripheral EA members"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# =====================================================================\n",
    "# PARAMETERS \u2014 CHANGE THESE TO MODIFY THE ANALYSIS\n",
    "# =====================================================================\n",
    "\n",
    "VAR_LAGS = 4            # Lags in the VAR. Higher = longer memory, more data needed per window.\n",
    "FORECAST_HORIZON = 10   # Steps ahead for FEVD. 10 = two trading weeks.\n",
    "ROLLING_WINDOW = 200    # Trading days per window. 200 \u2248 10 months.\n",
    "STEP_SIZE = 5           # Advance between windows. 1 = daily (slow), 5 = weekly (fast).\n",
    "\n",
    "DATA_PATH = \"nav_test_clean.csv\"  # Relative to notebook location, or use absolute path\n",
    "\n",
    "# Country groupings \u2014 must match column names in the CSV\n",
    "EXTERNAL     = [\"US\", \"JP\", \"UK\"]\n",
    "EA_CORE      = [\"DE\", \"FR\"]\n",
    "EA_PERIPHERY = [\"IT\", \"ES\"]\n",
    "\n",
    "# Derived (don't change unless you change the above)\n",
    "EA = EA_CORE + EA_PERIPHERY\n",
    "ALL_COUNTRIES = EXTERNAL + EA\n",
    "\n",
    "# Colour scheme for charts (one colour per country)\n",
    "COLORS = {\n",
    "    \"US\": \"#003299\", \"JP\": \"#FFB400\", \"UK\": \"#FF4B00\",\n",
    "    \"DE\": \"#65B800\", \"FR\": \"#00B1EA\", \"IT\": \"#007816\", \"ES\": \"#8139C6\"\n",
    "}\n",
    "\n",
    "print(f\"Analysis covers {len(ALL_COUNTRIES)} countries: {ALL_COUNTRIES}\")\n",
    "print(f\"VAR({VAR_LAGS}), {FORECAST_HORIZON}-day horizon, {ROLLING_WINDOW}-day rolling window, step={STEP_SIZE}\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load & Explore the Data\n",
    "\n",
    "We load a CSV of **daily 10-year government bond yields** (in percent).\n",
    "Each row is a trading day. Columns are country ISO codes.\n",
    "\n",
    "The data runs from **January 1995 to ~2025**, giving us roughly 30 years of daily observations."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Load the yield data\n",
    "yields = pd.read_csv(DATA_PATH)\n",
    "yields['Date'] = pd.to_datetime(yields['Date'])\n",
    "yields = yields.sort_values('Date').reset_index(drop=True)\n",
    "\n",
    "# Keep only the columns we need\n",
    "cols_to_keep = ['Date'] + [c for c in ALL_COUNTRIES if c in yields.columns]\n",
    "yields = yields[cols_to_keep]\n",
    "\n",
    "# Convert to numeric (handles any stray text)\n",
    "for c in ALL_COUNTRIES:\n",
    "    yields[c] = pd.to_numeric(yields[c], errors='coerce')\n",
    "\n",
    "print(f\"Loaded {len(yields):,} daily observations\")\n",
    "print(f\"Date range: {yields['Date'].min().date()} to {yields['Date'].max().date()}\")\n",
    "print(f\"\\nColumns: {list(yields.columns)}\")\n",
    "print(f\"\\nMissing values per country:\")\n",
    "print(yields[ALL_COUNTRIES].isnull().sum())\n",
    "print(f\"\\nFirst 5 rows:\")\n",
    "yields.head()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Plot raw yield levels\n",
    "fig, ax = plt.subplots(figsize=(14, 6))\n",
    "for c in ALL_COUNTRIES:\n",
    "    ax.plot(yields['Date'], yields[c], label=c, color=COLORS[c], linewidth=0.8)\n",
    "ax.set_xlabel('Date')\n",
    "ax.set_ylabel('10-Year Government Bond Yield (%)')\n",
    "ax.set_title('Raw Bond Yields: All Countries (1995\u20132025)', fontweight='bold')\n",
    "ax.legend(ncol=4, loc='upper right')\n",
    "ax.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Preparation \u2014 Why We Use Yield *Changes*\n",
    "\n",
    "**Critical assumption:** VAR models require (approximately) stationary data.\n",
    "Bond yield *levels* are non-stationary (they trend and have unit roots).\n",
    "Yield *changes* (first differences: today's yield minus yesterday's) are stationary.\n",
    "\n",
    "$$\\Delta y_t = y_t - y_{t-1}$$\n",
    "\n",
    "**If you used levels instead**, the VAR would produce unreliable results \u2014 spurious\n",
    "relationships, inflated t-statistics, and meaningless spillover estimates.\n",
    "\n",
    "The cell below computes daily yield changes and drops the first row (which becomes NaN)."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Compute first differences (yield changes)\n",
    "yield_changes = yields.copy()\n",
    "for c in ALL_COUNTRIES:\n",
    "    yield_changes[c] = yields[c].diff()\n",
    "\n",
    "# Drop the first row (NaN from differencing)\n",
    "yield_changes = yield_changes.dropna(subset=ALL_COUNTRIES).reset_index(drop=True)\n",
    "\n",
    "print(f\"Yield changes: {len(yield_changes):,} observations\")\n",
    "print(f\"\\nSummary statistics of daily yield changes (basis points \u00d7 100):\")\n",
    "print(yield_changes[ALL_COUNTRIES].describe().round(4))"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Plot yield changes\n",
    "fig, axes = plt.subplots(len(ALL_COUNTRIES), 1, figsize=(14, 2*len(ALL_COUNTRIES)), sharex=True)\n",
    "for i, c in enumerate(ALL_COUNTRIES):\n",
    "    axes[i].plot(yield_changes['Date'], yield_changes[c], color=COLORS[c], linewidth=0.3)\n",
    "    axes[i].set_ylabel(c, fontsize=10, fontweight='bold')\n",
    "    axes[i].grid(alpha=0.2)\n",
    "    axes[i].axhline(0, color='black', linewidth=0.3)\n",
    "axes[-1].set_xlabel('Date')\n",
    "fig.suptitle('Daily Yield Changes by Country', fontsize=14, fontweight='bold', y=1.01)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Methodology: Generalized Forecast Error Variance Decomposition\n",
    "\n",
    "This is the most important section to understand. Read carefully.\n",
    "\n",
    "### What is a VAR model?\n",
    "\n",
    "A **Vector Autoregression (VAR)** is a system of equations where each variable depends on\n",
    "its own past values AND the past values of all other variables:\n",
    "\n",
    "$$\\Delta y_t = A_1 \\Delta y_{t-1} + A_2 \\Delta y_{t-2} + ... + A_p \\Delta y_{t-p} + u_t$$\n",
    "\n",
    "where:\n",
    "- $\\Delta y_t$ is a vector of yield changes for all 7 countries on day $t$\n",
    "- $A_1, ..., A_p$ are coefficient matrices (estimated from data)\n",
    "- $p$ = number of lags (our `VAR_LAGS` parameter)\n",
    "- $u_t$ = residual shocks (the \"surprise\" component)\n",
    "\n",
    "### What is Forecast Error Variance Decomposition (FEVD)?\n",
    "\n",
    "Once we estimate the VAR, we can ask: **\"If I forecast German yields 10 days ahead,\n",
    "how much of my forecast error is due to shocks from the US? From France? From Italy?\"**\n",
    "\n",
    "The FEVD matrix $\\Theta$ is a $k \\times k$ matrix where:\n",
    "- $\\Theta_{ij}$ = percentage of country $i$'s forecast error variance explained by shocks from country $j$\n",
    "- Each row sums to 100%\n",
    "- Diagonal elements = \"own\" effects (how much of Germany's variance is from German shocks)\n",
    "- Off-diagonal elements = **spillovers** (how much of Germany's variance is from *other* countries' shocks)\n",
    "\n",
    "### Why \"Generalized\"?\n",
    "\n",
    "The traditional (Cholesky) FEVD **depends on the ordering of variables**. If you put the US\n",
    "first, you get different results than if you put Germany first. This is arbitrary and problematic.\n",
    "\n",
    "The **Generalized FEVD** (Pesaran & Shin, 1998) solves this by using each variable's own shock\n",
    "as the conditioning variable. The result is **order-invariant** \u2014 you get the same answer\n",
    "regardless of how you order the countries.\n",
    "\n",
    "*Trade-off:* Generalized FEVD rows don't naturally sum to 100%, so we normalise them.\n",
    "This is standard practice (Diebold & Yilmaz, 2012).\n",
    "\n",
    "### How Spillover Indices are Derived\n",
    "\n",
    "From the FEVD matrix $\\Theta$, we compute:\n",
    "\n",
    "| Measure | Formula | Interpretation |\n",
    "|---------|---------|---------------|\n",
    "| **Total Spillover Index** | $\\frac{\\sum_{i \\neq j} \\Theta_{ij}}{k}$ | Overall interconnectedness (0\u2013100%). Higher = more integrated. |\n",
    "| **TO others** (country $j$) | $\\sum_{i \\neq j} \\Theta_{ij}$ (column $j$ sum minus diagonal) | How much country $j$ transmits to all others combined |\n",
    "| **FROM others** (country $i$) | $\\sum_{j \\neq i} \\Theta_{ij}$ (row $i$ sum minus diagonal) | How much country $i$ receives from all others combined |\n",
    "| **Net** (country $j$) | TO $-$ FROM | Positive = **net transmitter**, Negative = **net receiver** |\n",
    "| **Bilateral** $\\Theta_{ij}$ | Single cell | How much of country $i$'s variance comes from country $j$'s shocks |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Core Functions\n",
    "\n",
    "The three functions below implement the entire spillover methodology.\n",
    "You should not need to change these unless you want to modify the methodology itself."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def generalized_fevd(var_result, H=10):\n",
    "    \"\"\"\n",
    "    Compute Generalized Forecast Error Variance Decomposition.\n",
    "    Based on Pesaran & Shin (1998), as used in Diebold-Yilmaz (2012).\n",
    "    This is ORDER-INVARIANT \u2014 results don't depend on variable ordering.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    var_result : statsmodels VARResults object (from model.fit())\n",
    "    H : int\n",
    "        Forecast horizon in days. Default 10 (2 trading weeks).\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    theta_normalized : numpy array (k \u00d7 k)\n",
    "        GFEVD matrix. theta[i,j] = % of country i's forecast error variance\n",
    "        explained by shocks from country j. Rows sum to 100.\n",
    "    \"\"\"\n",
    "    k = var_result.neqs       # Number of variables (countries)\n",
    "    p = var_result.k_ar       # Number of VAR lags\n",
    "    A = var_result.coefs      # Coefficient matrices, shape (p, k, k)\n",
    "    \n",
    "    # Residual covariance matrix \u03a3\n",
    "    sigma = var_result.sigma_u\n",
    "    if hasattr(sigma, 'values'):\n",
    "        sigma = sigma.values   # statsmodels sometimes returns a DataFrame\n",
    "    sigma_diag = np.diag(sigma)  # Diagonal = each variable's residual variance (\u03c3\u00b2_jj)\n",
    "    \n",
    "    # --- Step 1: Moving Average (MA) representation ---\n",
    "    # The VAR can be rewritten as an infinite MA process:\n",
    "    #   \u0394y_t = \u03a6_0 u_t + \u03a6_1 u_{t-1} + \u03a6_2 u_{t-2} + ...\n",
    "    # where \u03a6_0 = I (identity), and \u03a6_s is computed recursively.\n",
    "    Phi = np.zeros((H + 1, k, k))\n",
    "    Phi[0] = np.eye(k)\n",
    "    \n",
    "    for s in range(1, H + 1):\n",
    "        for j in range(1, min(s, p) + 1):\n",
    "            Phi[s] += Phi[s - j] @ A[j - 1]\n",
    "    \n",
    "    # --- Step 2: Generalized FEVD ---\n",
    "    # For each (i, j) pair, compute what fraction of i's H-step forecast error\n",
    "    # variance is attributable to shocks from j.\n",
    "    #\n",
    "    # Formula: \u03b8_ij = [\u03c3_jj^{-1} \u00d7 \u03a3_{h=0}^{H-1} (e_i' \u03a6_h \u03a3 e_j)\u00b2]\n",
    "    #                 / [\u03a3_{h=0}^{H-1} (e_i' \u03a6_h \u03a3 \u03a6_h' e_i)]\n",
    "    theta = np.zeros((k, k))\n",
    "    \n",
    "    for i in range(k):\n",
    "        # Denominator: TOTAL forecast error variance for variable i at horizon H\n",
    "        denom = 0\n",
    "        for h in range(H):\n",
    "            denom += Phi[h][i, :] @ sigma @ Phi[h][i, :].T\n",
    "        \n",
    "        for j in range(k):\n",
    "            # Numerator: contribution of shock j to variable i's forecast error\n",
    "            numer = 0\n",
    "            for h in range(H):\n",
    "                numer += (Phi[h][i, :] @ sigma[:, j]) ** 2\n",
    "            \n",
    "            theta[i, j] = (numer / sigma_diag[j]) / denom if denom > 0 else 0\n",
    "    \n",
    "    # --- Step 3: Normalise ---\n",
    "    # Generalized FEVD rows don't sum to 1 (unlike Cholesky).\n",
    "    # We normalise each row to sum to 100%, following Diebold-Yilmaz (2012).\n",
    "    row_sums = theta.sum(axis=1, keepdims=True)\n",
    "    row_sums[row_sums == 0] = 1\n",
    "    theta_normalized = 100 * theta / row_sums\n",
    "    \n",
    "    return theta_normalized\n",
    "\n",
    "print(\"generalized_fevd() defined.\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def compute_spillover_indices(theta, var_names):\n",
    "    \"\"\"\n",
    "    From a GFEVD matrix, compute all the Diebold-Yilmaz spillover measures.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    theta : numpy array (k \u00d7 k), GFEVD matrix (rows sum to 100)\n",
    "    var_names : list of str, country names matching theta rows/columns\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    dict with keys:\n",
    "        'total_spillover' : float (0\u2013100)\n",
    "        'to_others'       : dict {country: value}  \u2014 how much each transmits\n",
    "        'from_others'     : dict {country: value}  \u2014 how much each receives\n",
    "        'net'             : dict {country: value}  \u2014 to minus from\n",
    "        'pairwise'        : dict {f'{j}_to_{i}': value}  \u2014 bilateral spillovers\n",
    "        'theta'           : the original GFEVD matrix\n",
    "    \"\"\"\n",
    "    k = len(var_names)\n",
    "    \n",
    "    # Total Spillover Index = sum of off-diagonal / k\n",
    "    off_diag_sum = theta.sum() - np.trace(theta)\n",
    "    total_spillover = off_diag_sum / k\n",
    "    \n",
    "    # Directional TO others = column sum minus diagonal\n",
    "    to_others = theta.sum(axis=0) - np.diag(theta)\n",
    "    \n",
    "    # Directional FROM others = row sum minus diagonal\n",
    "    from_others = theta.sum(axis=1) - np.diag(theta)\n",
    "    \n",
    "    # Net = TO - FROM (positive = net transmitter)\n",
    "    net = to_others - from_others\n",
    "    \n",
    "    # Bilateral (all i\u2260j pairs)\n",
    "    pairwise = {}\n",
    "    for i, name_i in enumerate(var_names):\n",
    "        for j, name_j in enumerate(var_names):\n",
    "            if i != j:\n",
    "                pairwise[f\"{name_j}_to_{name_i}\"] = theta[i, j]\n",
    "    \n",
    "    return {\n",
    "        'total_spillover': total_spillover,\n",
    "        'to_others': dict(zip(var_names, to_others)),\n",
    "        'from_others': dict(zip(var_names, from_others)),\n",
    "        'net': dict(zip(var_names, net)),\n",
    "        'pairwise': pairwise,\n",
    "        'theta': theta\n",
    "    }\n",
    "\n",
    "print(\"compute_spillover_indices() defined.\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def rolling_spillover_analysis(data, var_names, window=200, lag=4, horizon=10, step=5):\n",
    "    \"\"\"\n",
    "    Run the spillover analysis in rolling windows through time.\n",
    "    \n",
    "    For each window of `window` days, we:\n",
    "    1. Estimate a VAR(lag) on the yield changes in that window\n",
    "    2. Compute the Generalized FEVD\n",
    "    3. Extract all spillover indices\n",
    "    4. Move forward by `step` days and repeat\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data     : DataFrame with 'Date' column and country yield change columns\n",
    "    var_names: list of country column names\n",
    "    window   : int, rolling window size in trading days\n",
    "    lag      : int, VAR lag order\n",
    "    horizon  : int, FEVD forecast horizon\n",
    "    step     : int, days to advance between windows\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    DataFrame with one row per window, containing all spillover measures\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    n = len(data)\n",
    "    total_windows = (n - window) // step + 1\n",
    "    \n",
    "    for i, start in enumerate(range(0, n - window, step)):\n",
    "        if i % 100 == 0:\n",
    "            print(f\"  Window {i+1}/{total_windows} ({100*i/total_windows:.0f}%)\")\n",
    "        \n",
    "        end = start + window\n",
    "        window_data = data.iloc[start:end][var_names].dropna()\n",
    "        \n",
    "        # Require at least 90% non-missing data in the window\n",
    "        if len(window_data) < window * 0.9:\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            model = VAR(window_data)\n",
    "            var_result = model.fit(lag)\n",
    "            theta = generalized_fevd(var_result, H=horizon)\n",
    "            indices = compute_spillover_indices(theta, var_names)\n",
    "            \n",
    "            # Store the date of the LAST observation in the window\n",
    "            result = {\n",
    "                'Date': data.iloc[end - 1]['Date'],\n",
    "                'total_spillover': indices['total_spillover']\n",
    "            }\n",
    "            \n",
    "            # Directional measures per country\n",
    "            for name in var_names:\n",
    "                result[f'{name}_to'] = indices['to_others'][name]\n",
    "                result[f'{name}_from'] = indices['from_others'][name]\n",
    "                result[f'{name}_net'] = indices['net'][name]\n",
    "            \n",
    "            # All bilateral pairs\n",
    "            for key, val in indices['pairwise'].items():\n",
    "                result[key] = val\n",
    "            \n",
    "            results.append(result)\n",
    "        except:\n",
    "            continue  # Skip windows where VAR fails (e.g., singular matrix)\n",
    "    \n",
    "    print(f\"  Completed: {len(results)} windows estimated.\")\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "print(\"rolling_spillover_analysis() defined.\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Run the Rolling Spillover Analysis\n",
    "\n",
    "**This is the main computation.** It takes a few minutes depending on your `STEP_SIZE`:\n",
    "- `STEP_SIZE=1` \u2192 ~1,500 windows, takes ~10 minutes\n",
    "- `STEP_SIZE=5` \u2192 ~300 windows, takes ~2 minutes  \u2190 default\n",
    "\n",
    "The progress counter prints every 100 windows so you can track it."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "%%time\n",
    "\n",
    "print(f\"Running rolling spillover analysis...\")\n",
    "print(f\"  VAR({VAR_LAGS}), horizon={FORECAST_HORIZON}, window={ROLLING_WINDOW}, step={STEP_SIZE}\")\n",
    "print(f\"  Data: {len(yield_changes):,} observations of yield changes\\n\")\n",
    "\n",
    "roll_df = rolling_spillover_analysis(\n",
    "    yield_changes,\n",
    "    ALL_COUNTRIES,\n",
    "    window=ROLLING_WINDOW,\n",
    "    lag=VAR_LAGS,\n",
    "    horizon=FORECAST_HORIZON,\n",
    "    step=STEP_SIZE\n",
    ")\n",
    "\n",
    "roll_df['Date'] = pd.to_datetime(roll_df['Date'])\n",
    "print(f\"\\nResult: {len(roll_df)} time points from {roll_df['Date'].min().date()} to {roll_df['Date'].max().date()}\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Full-Sample FEVD Table\n",
    "\n",
    "Before looking at time-varying results, let's see the **average** spillover structure\n",
    "over the entire sample. This gives us the \"big picture\" of who affects whom.\n",
    "\n",
    "**How to read the table:**\n",
    "- Row = the *receiver* (affected country)\n",
    "- Column = the *transmitter* (source of shock)\n",
    "- Cell value = % of the receiver's forecast error variance explained by the transmitter's shocks\n",
    "- Diagonal = \"own\" effects\n",
    "- Off-diagonal = spillovers"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Estimate a single VAR on the FULL sample\n",
    "full_sample = yield_changes[ALL_COUNTRIES].dropna()\n",
    "model = VAR(full_sample)\n",
    "var_full = model.fit(VAR_LAGS)\n",
    "\n",
    "# Compute GFEVD\n",
    "theta_full = generalized_fevd(var_full, H=FORECAST_HORIZON)\n",
    "indices_full = compute_spillover_indices(theta_full, ALL_COUNTRIES)\n",
    "\n",
    "# Display as a formatted table\n",
    "fevd_table = pd.DataFrame(theta_full, index=ALL_COUNTRIES, columns=ALL_COUNTRIES).round(1)\n",
    "print(\"Full-Sample Generalized FEVD Matrix (%):\")\n",
    "print(\"Rows = receiver, Columns = transmitter\\n\")\n",
    "print(fevd_table.to_string())\n",
    "print(f\"\\nTotal Spillover Index: {indices_full['total_spillover']:.1f}%\")\n",
    "\n",
    "# Heatmap\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "im = ax.imshow(theta_full, cmap='YlOrRd', vmin=0, vmax=30)\n",
    "for i in range(len(ALL_COUNTRIES)):\n",
    "    for j in range(len(ALL_COUNTRIES)):\n",
    "        color = 'white' if theta_full[i,j] > 18 else 'black'\n",
    "        ax.text(j, i, f'{theta_full[i,j]:.1f}', ha='center', va='center', fontsize=9, color=color)\n",
    "ax.set_xticks(range(len(ALL_COUNTRIES)))\n",
    "ax.set_yticks(range(len(ALL_COUNTRIES)))\n",
    "ax.set_xticklabels(ALL_COUNTRIES)\n",
    "ax.set_yticklabels(ALL_COUNTRIES)\n",
    "ax.set_xlabel('Transmitter (shock origin)', fontsize=11)\n",
    "ax.set_ylabel('Receiver (affected market)', fontsize=11)\n",
    "ax.set_title('Full-Sample GFEVD Matrix', fontweight='bold')\n",
    "plt.colorbar(im, label='Spillover (%)')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Total Spillover Index Over Time\n",
    "\n",
    "The **Total Spillover Index** captures overall market interconnectedness.\n",
    "- Higher values = bond markets are more tightly linked (shocks propagate more)\n",
    "- Lower values = markets are more segmented\n",
    "\n",
    "Key patterns to look for:\n",
    "- **Rising trend** during EMU convergence (late 1990s) and global tightening (2022+)\n",
    "- **Sharp drops** during the Euro crisis (2010\u20132012) \u2014 markets fragmented\n",
    "- **Spikes** during global events (GFC 2008, COVID 2020)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "fig, ax = plt.subplots(figsize=(14, 5))\n",
    "ax.plot(roll_df['Date'], roll_df['total_spillover'], color='#003299', linewidth=1.2)\n",
    "ax.fill_between(roll_df['Date'], roll_df['total_spillover'], alpha=0.3, color='#003299')\n",
    "ax.set_xlabel('Date')\n",
    "ax.set_ylabel('Total Spillover Index (%)')\n",
    "ax.set_title('Diebold-Yilmaz Total Spillover Index (Generalized FEVD)', fontweight='bold')\n",
    "ax.grid(alpha=0.3)\n",
    "\n",
    "# Print current level\n",
    "latest = roll_df.iloc[-1]\n",
    "print(f\"Latest total spillover: {latest['total_spillover']:.1f}% ({latest['Date'].date()})\")\n",
    "print(f\"Sample average: {roll_df['total_spillover'].mean():.1f}%\")\n",
    "print(f\"Sample max: {roll_df['total_spillover'].max():.1f}%\")\n",
    "print(f\"Sample min: {roll_df['total_spillover'].min():.1f}%\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Net Spillovers by Country\n",
    "\n",
    "**Net spillover = TO others \u2212 FROM others.**\n",
    "- Positive = the country is a **net transmitter** (its shocks affect others more than it is affected)\n",
    "- Negative = the country is a **net receiver** (it absorbs shocks from others)\n",
    "\n",
    "This tells us which countries are \"driving\" bond markets and which are \"following\"."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "fig, axes = plt.subplots(2, 1, figsize=(14, 9), sharex=True)\n",
    "\n",
    "# External countries\n",
    "for c in EXTERNAL:\n",
    "    axes[0].plot(roll_df['Date'], roll_df[f'{c}_net'], color=COLORS[c], linewidth=1.2, label=c)\n",
    "axes[0].axhline(0, color='black', linewidth=0.5)\n",
    "axes[0].set_ylabel('Net Spillover')\n",
    "axes[0].set_title('Net Spillovers: External Countries (+ = net transmitter)', fontweight='bold')\n",
    "axes[0].legend(loc='upper right')\n",
    "axes[0].grid(alpha=0.3)\n",
    "\n",
    "# EA countries\n",
    "for c in EA:\n",
    "    axes[1].plot(roll_df['Date'], roll_df[f'{c}_net'], color=COLORS[c], linewidth=1.2, label=c)\n",
    "axes[1].axhline(0, color='black', linewidth=0.5)\n",
    "axes[1].set_xlabel('Date')\n",
    "axes[1].set_ylabel('Net Spillover')\n",
    "axes[1].set_title('Net Spillovers: Euro Area Countries (+ = net transmitter)', fontweight='bold')\n",
    "axes[1].legend(loc='upper right')\n",
    "axes[1].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Summary table of average net positions\n",
    "print(\"\\nAverage net spillover positions (full sample):\")\n",
    "for c in ALL_COUNTRIES:\n",
    "    avg = roll_df[f'{c}_net'].mean()\n",
    "    role = \"NET TRANSMITTER\" if avg > 0 else \"net receiver\"\n",
    "    print(f\"  {c:3s}: {avg:+.1f}  ({role})\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. External vs Internal Spillovers to the Euro Area\n",
    "\n",
    "This section answers: **\"Are EA bond markets driven more by shocks from outside (US, UK, Japan)\n",
    "or from within the EA itself?\"**\n",
    "\n",
    "### How the averages are computed\n",
    "\n",
    "We compute the **average bilateral spillover** across all relevant pairs:\n",
    "\n",
    "- **External \u2192 EA (average):** For each of the 3 external \u00d7 4 EA = 12 pairs, take $\\Theta_{ij}$, then average. This answers: *\"On average, how much does a single external country's shock explain of a single EA country's variance?\"*\n",
    "\n",
    "- **Within EA (average):** For each of the 4 \u00d7 3 = 12 intra-EA pairs, take $\\Theta_{ij}$, then average. Same interpretation but for intra-EA shocks.\n",
    "\n",
    "- **Individual source (e.g. US \u2192 EA):** Average US \u2192 DE, US \u2192 FR, US \u2192 IT, US \u2192 ES. This answers: *\"On average, how much does a US shock explain of an EA country's variance?\"*\n",
    "\n",
    "**Important note:** These are *averages per pair*, not totals. To get TOTAL external influence on a given EA country, you would sum across external sources (e.g., US\u2192DE + JP\u2192DE + UK\u2192DE). We show both below."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Compute external vs internal spillovers\n",
    "ext_to_ea_cols = [f'{ext}_to_{ea}' for ea in EA for ext in EXTERNAL if f'{ext}_to_{ea}' in roll_df.columns]\n",
    "int_ea_cols = [f'{ea1}_to_{ea2}' for ea2 in EA for ea1 in EA if ea1 != ea2 and f'{ea1}_to_{ea2}' in roll_df.columns]\n",
    "\n",
    "# Average per pair\n",
    "external_avg = roll_df[ext_to_ea_cols].mean(axis=1)\n",
    "internal_avg = roll_df[int_ea_cols].mean(axis=1)\n",
    "\n",
    "# Individual external sources \u2192 EA average\n",
    "us_to_ea = roll_df[[f'US_to_{ea}' for ea in EA if f'US_to_{ea}' in roll_df.columns]].mean(axis=1)\n",
    "jp_to_ea = roll_df[[f'JP_to_{ea}' for ea in EA if f'JP_to_{ea}' in roll_df.columns]].mean(axis=1)\n",
    "uk_to_ea = roll_df[[f'UK_to_{ea}' for ea in EA if f'UK_to_{ea}' in roll_df.columns]].mean(axis=1)\n",
    "\n",
    "# Total external spillover TO each EA country (summed, not averaged)\n",
    "for ea in EA:\n",
    "    ext_cols = [f'{ext}_to_{ea}' for ext in EXTERNAL if f'{ext}_to_{ea}' in roll_df.columns]\n",
    "    int_cols = [f'{ea2}_to_{ea}' for ea2 in EA if ea2 != ea and f'{ea2}_to_{ea}' in roll_df.columns]\n",
    "    print(f\"{ea}: avg total external = {roll_df[ext_cols].sum(axis=1).mean():.1f}% \"\n",
    "          f\"(sum of {len(ext_cols)} sources), \"\n",
    "          f\"avg total internal = {roll_df[int_cols].sum(axis=1).mean():.1f}% \"\n",
    "          f\"(sum of {len(int_cols)} sources)\")\n",
    "\n",
    "# Plot: Average per pair comparison\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "axes[0].plot(roll_df['Date'], internal_avg, color='#222222', linewidth=1.5, label='Within EA (avg per pair)')\n",
    "axes[0].plot(roll_df['Date'], external_avg, color='#999999', linewidth=1.5, label='External \u2192 EA (avg per pair)')\n",
    "axes[0].set_xlabel('Date')\n",
    "axes[0].set_ylabel('Average Bilateral Spillover (%)')\n",
    "axes[0].set_title('External vs Internal (Average Per Pair)', fontweight='bold')\n",
    "axes[0].legend()\n",
    "axes[0].grid(alpha=0.3)\n",
    "\n",
    "# Plot: Individual external sources\n",
    "axes[1].plot(roll_df['Date'], us_to_ea, color=COLORS['US'], linewidth=1.2, label='US \u2192 EA')\n",
    "axes[1].plot(roll_df['Date'], jp_to_ea, color=COLORS['JP'], linewidth=1.2, label='JP \u2192 EA')\n",
    "axes[1].plot(roll_df['Date'], uk_to_ea, color=COLORS['UK'], linewidth=1.2, label='UK \u2192 EA')\n",
    "axes[1].set_xlabel('Date')\n",
    "axes[1].set_ylabel('Average Spillover to EA (%)')\n",
    "axes[1].set_title('External Spillovers by Source Country', fontweight='bold')\n",
    "axes[1].legend()\n",
    "axes[1].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Core\u2013Periphery Dynamics\n",
    "\n",
    "Within the Euro Area, we split countries into **core** (Germany, France) and\n",
    "**periphery** (Italy, Spain).\n",
    "\n",
    "This matters because:\n",
    "- During crises, core and periphery can **decouple** (fragmentation)\n",
    "- During normal times, spillovers flow in both directions (integration)\n",
    "- The **direction** of spillovers reveals power dynamics"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Core \u2192 Periphery spillovers\n",
    "c2p_cols = [f'{core}_to_{periph}' for core in EA_CORE for periph in EA_PERIPHERY \n",
    "            if f'{core}_to_{periph}' in roll_df.columns]\n",
    "p2c_cols = [f'{periph}_to_{core}' for periph in EA_PERIPHERY for core in EA_CORE \n",
    "            if f'{periph}_to_{core}' in roll_df.columns]\n",
    "\n",
    "core_to_periph = roll_df[c2p_cols].mean(axis=1)\n",
    "periph_to_core = roll_df[p2c_cols].mean(axis=1)\n",
    "periph_net = periph_to_core - core_to_periph\n",
    "\n",
    "fig, axes = plt.subplots(2, 1, figsize=(14, 8), sharex=True)\n",
    "\n",
    "axes[0].plot(roll_df['Date'], core_to_periph, color=COLORS['DE'], linewidth=1.2, label='Core \u2192 Periphery')\n",
    "axes[0].plot(roll_df['Date'], periph_to_core, color=COLORS['IT'], linewidth=1.2, label='Periphery \u2192 Core')\n",
    "axes[0].set_ylabel('Average Spillover (%)')\n",
    "axes[0].set_title('Core\u2013Periphery Spillover Flows', fontweight='bold')\n",
    "axes[0].legend()\n",
    "axes[0].grid(alpha=0.3)\n",
    "\n",
    "axes[1].fill_between(roll_df['Date'], periph_net, where=periph_net >= 0, color=COLORS['IT'], alpha=0.5, label='Periphery net transmitter')\n",
    "axes[1].fill_between(roll_df['Date'], periph_net, where=periph_net < 0, color=COLORS['DE'], alpha=0.5, label='Core net transmitter')\n",
    "axes[1].plot(roll_df['Date'], periph_net, color='black', linewidth=0.8)\n",
    "axes[1].axhline(0, color='black', linewidth=0.5)\n",
    "axes[1].set_xlabel('Date')\n",
    "axes[1].set_ylabel('Net Spillover')\n",
    "axes[1].set_title('Periphery Net Position vs Core (+ = periphery transmits more)', fontweight='bold')\n",
    "axes[1].legend()\n",
    "axes[1].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Bilateral Spillover Matrices by Regime\n",
    "\n",
    "Here we compute the average FEVD matrix for specific historical periods.\n",
    "This shows how the *structure* of spillovers changes across regimes.\n",
    "\n",
    "**Regimes defined:**\n",
    "- **Euro Crisis (2010\u20132012):** Sovereign debt crisis, fragmentation\n",
    "- **QE Era (2015\u20132019):** ECB QE, low rates, convergence\n",
    "- **Tightening (2022\u20132025):** Post-COVID hiking cycle"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "regimes = {\n",
    "    'Full Sample': (roll_df['Date'].min(), roll_df['Date'].max()),\n",
    "    'Euro Crisis (2010-2012)': (pd.Timestamp('2010-01-01'), pd.Timestamp('2012-12-31')),\n",
    "    'QE Era (2015-2019)': (pd.Timestamp('2015-01-01'), pd.Timestamp('2019-12-31')),\n",
    "    'Tightening (2022-2025)': (pd.Timestamp('2022-01-01'), pd.Timestamp('2025-12-31')),\n",
    "}\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, (name, (start, end)) in enumerate(regimes.items()):\n",
    "    # Get period data and estimate VAR\n",
    "    mask = (yield_changes['Date'] >= start) & (yield_changes['Date'] <= end)\n",
    "    period_data = yield_changes[mask][ALL_COUNTRIES].dropna()\n",
    "    \n",
    "    if len(period_data) < 100:\n",
    "        axes[idx].text(0.5, 0.5, 'Insufficient data', ha='center', va='center')\n",
    "        continue\n",
    "    \n",
    "    model = VAR(period_data)\n",
    "    var_result = model.fit(VAR_LAGS)\n",
    "    theta = generalized_fevd(var_result, H=FORECAST_HORIZON)\n",
    "    \n",
    "    im = axes[idx].imshow(theta, cmap='YlOrRd', aspect='auto', vmin=0, vmax=25)\n",
    "    for i in range(len(ALL_COUNTRIES)):\n",
    "        for j in range(len(ALL_COUNTRIES)):\n",
    "            if i != j:\n",
    "                color = 'white' if theta[i,j] > 15 else 'black'\n",
    "                axes[idx].text(j, i, f'{theta[i,j]:.1f}', ha='center', va='center', fontsize=7, color=color)\n",
    "    \n",
    "    axes[idx].set_xticks(range(len(ALL_COUNTRIES)))\n",
    "    axes[idx].set_yticks(range(len(ALL_COUNTRIES)))\n",
    "    axes[idx].set_xticklabels(ALL_COUNTRIES, fontsize=8)\n",
    "    axes[idx].set_yticklabels(ALL_COUNTRIES, fontsize=8)\n",
    "    axes[idx].set_title(name, fontsize=10, fontweight='bold')\n",
    "\n",
    "fig.subplots_adjust(right=0.88)\n",
    "cbar_ax = fig.add_axes([0.90, 0.15, 0.02, 0.7])\n",
    "fig.colorbar(im, cax=cbar_ax, label='Spillover (%)')\n",
    "fig.suptitle('Bilateral Spillover Matrices by Regime', fontsize=13, fontweight='bold', y=0.98)\n",
    "plt.show()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. Regime Comparison Summary\n",
    "\n",
    "Average spillover measures across different policy regimes."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "regime_defs = {\n",
    "    'Pre-Draghi (2010-2012)': ('2010-01-01', '2012-07-25'),\n",
    "    'QE Era (2015-2019)': ('2015-01-01', '2019-12-31'),\n",
    "    'COVID/PEPP (2020-2021)': ('2020-01-01', '2021-12-31'),\n",
    "    'Tightening (2022-2023)': ('2022-01-01', '2023-12-31'),\n",
    "    'Cutting Cycle (2024+)': ('2024-01-01', '2025-12-31'),\n",
    "}\n",
    "\n",
    "rows = []\n",
    "for name, (start, end) in regime_defs.items():\n",
    "    mask = (roll_df['Date'] >= start) & (roll_df['Date'] <= end)\n",
    "    rd = roll_df[mask]\n",
    "    if len(rd) == 0:\n",
    "        continue\n",
    "    row = {'Regime': name, 'N windows': len(rd), 'Total Spillover': rd['total_spillover'].mean()}\n",
    "    for c in ALL_COUNTRIES:\n",
    "        row[f'{c} net'] = rd[f'{c}_net'].mean()\n",
    "    rows.append(row)\n",
    "\n",
    "regime_table = pd.DataFrame(rows).set_index('Regime')\n",
    "print(regime_table.round(1).to_string())\n",
    "\n",
    "# Bar chart\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "ax.bar(regime_table.index, regime_table['Total Spillover'], color='#003299', alpha=0.8)\n",
    "ax.set_ylabel('Total Spillover Index (%)')\n",
    "ax.set_title('Average Total Spillover by Regime', fontweight='bold')\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "plt.xticks(rotation=30, ha='right')\n",
    "for i, v in enumerate(regime_table['Total Spillover']):\n",
    "    ax.text(i, v + 0.3, f'{v:.1f}', ha='center', fontsize=10)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15. Key Findings\n",
    "\n",
    "The analysis above typically reveals several patterns (verify with your own output):\n",
    "\n",
    "1. **Spillover intensity has increased** \u2014 bond markets are more interconnected now than in the 1990s\n",
    "2. **The US is the dominant external transmitter** to EA bond markets\n",
    "3. **Internal EA spillovers exceed external ones** \u2014 EA countries affect each other more than outsiders affect them\n",
    "4. **Germany and France are the key transmitters** within the EA; Italy and Spain are net receivers\n",
    "5. **The Euro crisis (2010\u20132012) saw fragmentation** \u2014 total spillovers dropped as core and periphery decoupled\n",
    "6. **Japan has decoupled post-YCC** \u2014 JP\u2192EA spillovers fell sharply after the Bank of Japan ended yield curve control\n",
    "7. **France acts as a pivot** between core and periphery, transmitting shocks in both directions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16. Export Results\n",
    "\n",
    "Save all outputs to CSV and Excel for further analysis or sharing."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from pathlib import Path\n",
    "out_dir = Path(\"notebook_output\")\n",
    "out_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Save rolling spillovers\n",
    "roll_df.to_csv(out_dir / \"rolling_spillovers.csv\", index=False)\n",
    "print(f\"Saved: rolling_spillovers.csv ({len(roll_df)} rows)\")\n",
    "\n",
    "# Save full-sample FEVD table\n",
    "fevd_table.to_csv(out_dir / \"full_sample_fevd.csv\")\n",
    "print(f\"Saved: full_sample_fevd.csv\")\n",
    "\n",
    "# Save regime statistics\n",
    "regime_table.to_csv(out_dir / \"regime_statistics.csv\")\n",
    "print(f\"Saved: regime_statistics.csv\")\n",
    "\n",
    "# Save monthly external spillovers to US (Excel)\n",
    "roll_monthly = roll_df.copy()\n",
    "roll_monthly['YearMonth'] = roll_monthly['Date'].dt.to_period('M')\n",
    "\n",
    "ext_to_us_cols = [c for c in roll_df.columns if c.endswith('_to_US')]\n",
    "monthly_agg = roll_monthly.groupby('YearMonth')[ext_to_us_cols].mean()\n",
    "monthly_agg['Total_External_to_US'] = monthly_agg.sum(axis=1)\n",
    "monthly_agg.index = monthly_agg.index.to_timestamp()\n",
    "\n",
    "with pd.ExcelWriter(out_dir / \"external_spillovers_to_us_monthly.xlsx\", engine='openpyxl') as writer:\n",
    "    monthly_agg.to_excel(writer, sheet_name='Monthly External to US')\n",
    "print(f\"Saved: external_spillovers_to_us_monthly.xlsx\")\n",
    "\n",
    "print(f\"\\nAll outputs in: {out_dir.resolve()}\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix: How to Modify This Analysis\n",
    "\n",
    "| I want to... | Change this... | In Section... |\n",
    "|--------------|---------------|---------------|\n",
    "| Use different countries | Edit `EXTERNAL`, `EA_CORE`, `EA_PERIPHERY` lists | Section 2 |\n",
    "| Use a different CSV file | Change `DATA_PATH` | Section 2 |\n",
    "| Use more/fewer VAR lags | Change `VAR_LAGS` | Section 2 |\n",
    "| Change the forecast horizon | Change `FORECAST_HORIZON` | Section 2 |\n",
    "| Make smoother/choppier time series | Increase/decrease `ROLLING_WINDOW` | Section 2 |\n",
    "| Speed up / slow down computation | Increase/decrease `STEP_SIZE` | Section 2 |\n",
    "| Add new regime periods | Edit `regime_defs` dict | Section 14 |\n",
    "| Change chart colours | Edit `COLORS` dict | Section 2 |\n",
    "| Use yield levels instead of changes | Remove the `.diff()` in Section 4 (NOT recommended) | Section 4 |\n",
    "| Use Cholesky instead of Generalized FEVD | Replace `generalized_fevd()` with statsmodels built-in `fevd()` | Section 6 |\n",
    "\n",
    "**After changing parameters**, re-run all cells from Section 7 onwards (Kernel \u2192 Restart & Run All)."
   ]
  }
 ]
}